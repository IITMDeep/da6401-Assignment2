{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8042345,"sourceType":"datasetVersion","datasetId":4741662},{"sourceId":8053062,"sourceType":"datasetVersion","datasetId":4749104},{"sourceId":11451444,"sourceType":"datasetVersion","datasetId":7174884}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport pytorch_lightning as L\nfrom torchvision import transforms, models,datasets\nimport cv2\nfrom pytorch_lightning.loggers import WandbLogger\nfrom torch.utils.data import Dataset, DataLoader ,random_split,Subset\nimport matplotlib.pyplot as plt \nimport torchvision.models as models\nimport torch.nn as nn \nimport torch.optim as optim \nfrom torchmetrics import MetricCollection, Accuracy\nimport torch.nn.functional as F\nimport torch\nimport os\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2025-04-21T18:16:12.920172Z","iopub.execute_input":"2025-04-21T18:16:12.920617Z","iopub.status.idle":"2025-04-21T18:16:31.108707Z","shell.execute_reply.started":"2025-04-21T18:16:12.920591Z","shell.execute_reply":"2025-04-21T18:16:31.108138Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.5' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!wandb login 6a66920f640c7001ec17ad4aa7a5da8b378aee61","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:16:31.110035Z","iopub.execute_input":"2025-04-21T18:16:31.110322Z","iopub.status.idle":"2025-04-21T18:16:32.501043Z","shell.execute_reply.started":"2025-04-21T18:16:31.110297Z","shell.execute_reply":"2025-04-21T18:16:32.500120Z"}},"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"sweep_config = {\n  'name': 'partB',\n  'method': 'bayes',\n  'metric': {\n      'name': 'val_acc',\n      'goal': 'maximize'\n    },\n  'parameters': {\n      'epochs': {\n            'values': [5]\n        },\n        'learning_rate': {\n            'values': [0.0015,0.0001, 0.01]\n        },\n        'batch_size': {\n            'values': [64]\n        },\n        'optimizer':{\n              'values': ['adam']\n        },\n        'model':{\n            'values':['ResNet50','InceptionV3']\n        },\n        'unfreeze_layers':{\n            'values':[0, 10, 25]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config,entity=\"cs24m019-iitm\",project=\"DL-Assignment-2\")","metadata":{"execution":{"iopub.status.busy":"2025-04-21T18:16:32.502092Z","iopub.execute_input":"2025-04-21T18:16:32.502368Z","iopub.status.idle":"2025-04-21T18:16:38.337614Z","shell.execute_reply.started":"2025-04-21T18:16:32.502340Z","shell.execute_reply":"2025-04-21T18:16:38.336936Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Create sweep with ID: 9wa5tyxt\nSweep URL: https://wandb.ai/cs24m019-iitm/DL-Assignment-2/sweeps/9wa5tyxt\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"class root_dataset(Dataset):\n    def __init__(self):\n        self.dataset1=datasets.ImageFolder(root='/kaggle/input/inatural-12k/inaturalist_12K/train')\n        l1=int(len(self.dataset1)*0.8)\n        train_dataset,val_dataset=random_split(self.dataset1, [int(len(self.dataset1)*0.8),len(self.dataset1)-l1])\n        #print(len(train_dataset),len(val_dataset))\n        self.train_dataset=train_dataset\n        self.val_dataset=val_dataset\n    def get_train_data(self):\n        return self.train_dataset\n    def get_val_data(self):\n        return self.val_dataset","metadata":{"execution":{"iopub.status.busy":"2025-04-21T18:16:38.339282Z","iopub.execute_input":"2025-04-21T18:16:38.339756Z","iopub.status.idle":"2025-04-21T18:16:38.344831Z","shell.execute_reply.started":"2025-04-21T18:16:38.339734Z","shell.execute_reply":"2025-04-21T18:16:38.344257Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class inaturalist_train(Dataset):\n    def __init__(self,train_data,model_name):\n        if model_name=='InceptionV3':\n            self.target_size=(3,299,299)\n        else:\n            self.target_size=(3,224,224)\n        #dataset1=datasets.ImageFolder(root='/kaggle/input/neurolist/inaturalist_12K/train')\n        self.dataset=train_data    \n        self.transform = transforms.Compose([\n            transforms.Resize(self.target_size[1:]),\n            transforms.ToTensor()\n        ])#self.target_size = target_size \n        \n    def __getitem__(self,idx):\n        image,label=self.dataset[idx]\n        image=self.transform(image)\n        return image,label\n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2025-04-21T18:16:38.345627Z","iopub.execute_input":"2025-04-21T18:16:38.345929Z","iopub.status.idle":"2025-04-21T18:16:38.479347Z","shell.execute_reply.started":"2025-04-21T18:16:38.345892Z","shell.execute_reply":"2025-04-21T18:16:38.478773Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class inaturalist_val(Dataset):\n    def __init__(self,val_data,model_name):\n        if model_name=='InceptionV3':\n            self.target_size=(3,299,299)\n        else:\n            self.target_size=(3,224,224)\n        #dataset1=datasets.ImageFolder(root='/kaggle/input/neurolist/inaturalist_12K/train')\n        self.dataset=val_data\n        self.transform = transforms.Compose([\n            transforms.Resize(self.target_size[1:]),\n            transforms.ToTensor()\n        ])#self.target_size = target_size   \n    def __getitem__(self,idx):\n        image,label=self.dataset[idx]\n        image=self.transform(image)\n        return image,label\n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2025-04-21T18:16:38.480189Z","iopub.execute_input":"2025-04-21T18:16:38.480506Z","iopub.status.idle":"2025-04-21T18:16:38.506751Z","shell.execute_reply.started":"2025-04-21T18:16:38.480482Z","shell.execute_reply":"2025-04-21T18:16:38.506226Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class inaturalist_test(Dataset):\n    def __init__(self,model_name):\n        if model_name=='InceptionV3':\n            self.target_size=(3,299,299)\n        else:\n            self.target_size=(3,224,224)\n        self.dataset=datasets.ImageFolder(root='/kaggle/input/inatural-12k/inaturalist_12K/val')\n        self.transform = transforms.Compose([\n            transforms.Resize(self.target_size[1:]),  # Resize images to target size\n            transforms.ToTensor()\n        ])#self.target_size = target_size   \n    def __getitem__(self,idx):\n        image,label=self.dataset[idx]\n        image=self.transform(image)\n        return image,label\n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2025-04-21T18:16:38.507614Z","iopub.execute_input":"2025-04-21T18:16:38.507867Z","iopub.status.idle":"2025-04-21T18:16:38.528370Z","shell.execute_reply.started":"2025-04-21T18:16:38.507845Z","shell.execute_reply":"2025-04-21T18:16:38.527892Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class Activation_Function:\n    def activation_Function(self,activation_function):\n        if activation_function=='relu':\n            return F.relu\n        if activation_function=='gelu':\n            return F.gelu\n        if activation_function=='selu':\n            return F.selu\n        if activation_function=='elu':\n            return F.elu","metadata":{"execution":{"iopub.status.busy":"2025-04-21T18:16:38.529043Z","iopub.execute_input":"2025-04-21T18:16:38.529305Z","iopub.status.idle":"2025-04-21T18:16:38.553263Z","shell.execute_reply.started":"2025-04-21T18:16:38.529280Z","shell.execute_reply":"2025-04-21T18:16:38.552788Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class lightning_pretrained_CNN(L.LightningModule):\n    def __init__(self, model_name, unfreeze_layers, optimizer, learning_rate):\n        super().__init__()\n        self.learning_rate = learning_rate\n        self.optimizer = optimizer\n        self.model_name = model_name\n        \n        # Initialize model based on the model name provided\n        if self.model_name == 'ResNet50':\n            self.model = models.resnet50(pretrained=True)\n        elif self.model_name == 'GoogLeNet':\n            self.model = models.googlenet(pretrained=True)\n        elif self.model_name == 'InceptionV3':\n            self.model = models.inception_v3(pretrained=True, transform_input=True)\n        \n        # Freeze layers until the unfreeze_layers level\n        freeze_index = 0\n        for param in self.model.parameters():\n            if freeze_index < (len(list(self.model.parameters())) - (unfreeze_layers + 2)):\n                param.requires_grad = False\n            else:\n                break\n            freeze_index += 1\n        \n        # Adjust the final fully connected layer to match the number of output classes (10)\n        num_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_features, 10)\n    def forward(self, x):\n        return self.model(x)\n    \n    def training_step(self, batch, batch_idx):  # Training step\n        inputs, labels = batch\n        output = self.forward(inputs)\n        \n        if self.model_name == 'InceptionV3':\n            logits = output.logits\n            _, preds = torch.max(logits, dim=1)\n            loss = F.cross_entropy(logits, labels)  # Calculate loss\n        else:\n            logits = output\n            _, preds = torch.max(logits, dim=1)\n            loss = F.cross_entropy(logits, labels)\n        \n        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)  # Log training loss\n\n        return loss\n    def configure_optimizers(self):  # Configure optimizer based on provided arguments\n        if self.optimizer == 'adam':\n            optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        elif self.optimizer == 'nadam':\n            optimizer = torch.optim.NAdam(self.parameters(), lr=self.learning_rate)\n        elif self.optimizer == 'sgd':\n            optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n        else:\n            raise ValueError(f\"Unsupported optimizer: {self.optimizer}\")\n        \n        return optimizer\n        \n    def validation_step(self, batch, batch_idx):  # Validation step\n            x, y = batch\n            predictions = self.forward(x)  # Forward pass\n\n            # Calculate loss\n            validation_loss = F.cross_entropy(predictions, y)\n            \n            # Calculate accuracy\n            _, predicted_labels = torch.max(predictions, dim=1)\n            validation_accuracy = (predicted_labels == y).float().mean().item()\n\n            # Log the loss and accuracy during validation\n            self.log('val_loss', validation_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n            self.log('val_acc', validation_accuracy, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n\n            return validation_loss\n        \n    \n    def test_step(self, batch, batch_idx):  # Test step\n        x, y = batch\n        pred = self.forward(x)  # Forward pass\n        \n        loss = F.cross_entropy(pred, y)  # Compute loss\n        _, predicted = torch.max(pred.data, 1)  # Get predicted class labels\n        \n        # Calculate accuracy\n        accuracy = (predicted == y).float().mean().item()\n\n        # Logging the values\n        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log(\"test_accuracy\", accuracy, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n\n        return {\"test_loss\": loss}\n    ","metadata":{"execution":{"iopub.status.busy":"2025-04-21T18:16:38.553947Z","iopub.execute_input":"2025-04-21T18:16:38.554198Z","iopub.status.idle":"2025-04-21T18:16:38.571626Z","shell.execute_reply.started":"2025-04-21T18:16:38.554177Z","shell.execute_reply":"2025-04-21T18:16:38.571147Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def main(config=None):\n    with wandb.init(config=config, ):\n        config=wandb.config\n        wandb.run.name='bs-'+str(config.batch_size)+'-lr-'+ str(config.learning_rate)+'-ep-'+str(config.epochs)+ '-op-'+str(config.optimizer)+'-mn-'+str(config.model)+'-ul-'+str(config.unfreeze_layers)\n        model_name=config.model\n        root_obj=root_dataset()\n        train_data=root_obj.get_train_data()\n        val_data=root_obj.get_val_data()\n        dataset1=inaturalist_train(train_data,model_name)\n        dataset2=inaturalist_val(val_data,model_name)\n        dataset3=inaturalist_test(model_name)\n        b_size=config.batch_size\n        unfreeze_layers=config.unfreeze_layers\n        optimizer=config.optimizer\n        epoch=config.epochs\n        learning_rate=config.learning_rate\n        wandb_logger = WandbLogger(project='DL-Assignment-2', entity='cs24m019-iitm')\n        dataloader=DataLoader(dataset=dataset1,batch_size=b_size,shuffle=True,num_workers=2)\n        val_dataloader=DataLoader(dataset=dataset2,batch_size=b_size,shuffle=False,num_workers=2)\n        model=lightning_pretrained_CNN(model_name,unfreeze_layers,'adam',0.0015)\n        trainer = L.Trainer(accelerator='auto',devices=\"auto\",max_epochs=epoch,logger=wandb_logger)\n        trainer.fit(model,dataloader,val_dataloader)\n        test_dataloader=DataLoader(dataset=dataset3,batch_size=8,shuffle=False,num_workers=1)\n        trainer.test(dataloaders=test_dataloader)\n\n        ","metadata":{"execution":{"iopub.status.busy":"2025-04-21T18:16:38.573197Z","iopub.execute_input":"2025-04-21T18:16:38.573459Z","iopub.status.idle":"2025-04-21T18:16:38.597152Z","shell.execute_reply.started":"2025-04-21T18:16:38.573438Z","shell.execute_reply":"2025-04-21T18:16:38.596390Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"if  __name__ ==\"__main__\":\n    wandb.agent(sweep_id, main,count=30)\n    #main()","metadata":{"execution":{"iopub.status.busy":"2025-04-21T18:16:38.597944Z","iopub.execute_input":"2025-04-21T18:16:38.598172Z","execution_failed":"2025-04-21T18:17:08.999Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w89709ca with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet50\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tunfreeze_layers: 25\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m019\u001b[0m (\u001b[33mcs24m019-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250421_181644-w89709ca</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m019-iitm/DL-Assignment-2/runs/w89709ca' target=\"_blank\">clear-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m019-iitm/DL-Assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m019-iitm/DL-Assignment-2/sweeps/9wa5tyxt' target=\"_blank\">https://wandb.ai/cs24m019-iitm/DL-Assignment-2/sweeps/9wa5tyxt</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m019-iitm/DL-Assignment-2' target=\"_blank\">https://wandb.ai/cs24m019-iitm/DL-Assignment-2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m019-iitm/DL-Assignment-2/sweeps/9wa5tyxt' target=\"_blank\">https://wandb.ai/cs24m019-iitm/DL-Assignment-2/sweeps/9wa5tyxt</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m019-iitm/DL-Assignment-2/runs/w89709ca' target=\"_blank\">https://wandb.ai/cs24m019-iitm/DL-Assignment-2/runs/w89709ca</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 180MB/s] \n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afd1d0cabedf4f80b03777cbbd76496f"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}